{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 2: ES\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task2.2: An agent using evolved rules using ES\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab2` inside your personal course repository for the course \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pformat\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from tqdm.notebook import trange\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move definition, which row and number of object to remove\n",
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        if k == None:\n",
    "            self._k = self._rows[-1]\n",
    "        else:\n",
    "            self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    # action of removing\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert num_objects <= self._k\n",
    "        self._rows[row] -= num_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"A completely random move\"\"\"\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, min(state.rows[row], state.k))\n",
    "    return Nimply(row, num_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, min(c + 1, state.k))]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def nim_sum(state: Nim) -> int:\n",
    "    \"\"\"Compute the bitwise xor of the heaps. In the combinatorial game theory usually called the nim-sum\"\"\"\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "# compute for each possibile move the nim_sum and return a dictionary of possible_moves : { Numply: nim_sum , ... ,}\n",
    "def analize(raw: Nim) -> dict:\n",
    "    \"\"\"compute for each possibile move the nim_sum and return a dictionary of possible_moves : { Numply: nim_sum , ... ,}\"\"\"\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "    for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, min(c + 1, raw.k))):\n",
    "        tmp = deepcopy(raw)\n",
    "        tmp.nimming(ply)\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "    return cooked\n",
    "\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    \"\"\"The professor optimal solution\"\"\"\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "\n",
    "    # take only the moves that have nim_sum != 0\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0 and ply.num_objects <= state.k]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = [move for move in list(analysis[\"possible_moves\"].keys()) if move.num_objects <= state.k]\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1\n",
    "My implementation of Rule-Based agent based on Nim-Sum:\n",
    "\n",
    "Idea:\n",
    "We always play a move in order to have a nim-sum value of 0. \n",
    "At some point, we end up in a position that has only one row of size 2 or more.\n",
    "In such a position the nim-sum value is not equal to 0. To win we must reduce this to size 0 or 1, leaving an odd number of rows with size 1. From that point on, all moves are forced.\n",
    "\n",
    "Reference: https://en.wikipedia.org/wiki/Nim#Proof_of_the_winning_formula.\n",
    "\n",
    "The following function implements this winning strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expert_system(state: Nim) -> Nimply:\n",
    "    \"\"\"\n",
    "    Implementation of an expert system which beats the strategies defined above.\n",
    "    Details on how to win are available at https://en.wikipedia.org/wiki/Nim#Proof_of_the_winning_formula.\n",
    "\n",
    "    Args:\n",
    "        state: Nim game instance.\n",
    "\n",
    "    Returns:\n",
    "        The play to do.\n",
    "    \"\"\"\n",
    "    analysis = analize(state)\n",
    "    rows_not_zero = len(state.rows) - state.rows.count(0)\n",
    "    # case of one single row with lenght >= 2\n",
    "    if state.rows.count(1) == (rows_not_zero - 1):\n",
    "        row, num_objects = [(row, num_objects) for row, num_objects in enumerate(state.rows) if num_objects > 1][0]\n",
    "        if (rows_not_zero % 2) == 1:\n",
    "            num_objects = num_objects if (num_objects - 1) <= state.k else state.k\n",
    "            return Nimply(row, num_objects - 1)\n",
    "        else:\n",
    "            num_objects = num_objects if num_objects <= state.k else state.k\n",
    "            return Nimply(row, num_objects)\n",
    "    # case with more row with length >= 2\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns == 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = [move for move in list(analysis[\"possible_moves\"].keys())]\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(nim: Nim, strategy: tuple[Nimply]) -> int:\n",
    "    \"\"\"\n",
    "    Function to do a match.\n",
    "\n",
    "    Args:\n",
    "        nim: Nim game instance.\n",
    "        strategy: tuple of (player_strategy,opponent_strategy)\n",
    "    Returns:\n",
    "        The winner player.\n",
    "    \"\"\"\n",
    "\n",
    "    logging.getLogger().setLevel(logging.WARN)\n",
    "    logging.info(f\"init : {nim}\")\n",
    "    player = 0\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        logging.info(f\"ply: player {player} plays {ply}\")\n",
    "        nim.nimming(ply)\n",
    "        logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    logging.info(f\"status: Player {player} won!\")\n",
    "    return player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(nim: Nim, player_strategy: Nimply, opponent_strategies: tuple[Nimply], number_of_games: int) -> None:\n",
    "    \"\"\"\n",
    "    Function to test a strategy.\n",
    "\n",
    "    Args:\n",
    "        nim: Nim game instance.\n",
    "        player_strategy: the player strategy.\n",
    "        opponent_strategy: a tupla of the opponent strategies.\n",
    "        number_of_games: number of games to play.\n",
    "    Returns:\n",
    "        A print of percentage of win of the player strategy vs all the opponent strategies.\n",
    "    \"\"\"\n",
    "    for strategy in opponent_strategies:\n",
    "        wins = 0\n",
    "        for _ in range(number_of_games):\n",
    "            tmp = deepcopy(nim)\n",
    "\n",
    "            winner = match(tmp, (player_strategy, strategy))\n",
    "\n",
    "            if winner == 0:\n",
    "                wins += 1\n",
    "\n",
    "        print(f\"Win-rate of {player_strategy.__qualname__} vs {strategy.__qualname__}: {(wins / number_of_games):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 0 with strategy expert_system vs Player 1 with strategy optimal: 95.00% win rate\n",
      "Player 0 with strategy expert_system vs Player 1 with strategy pure_random: 88.00% win rate\n",
      "Player 0 with strategy expert_system vs Player 1 with strategy gabriele: 93.00% win rate\n"
     ]
    }
   ],
   "source": [
    "nim = Nim(5, 3)\n",
    "opponent_strategys = (optimal, pure_random, gabriele)\n",
    "test(nim, expert_system, opponent_strategys, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2\n",
    "My implementation of Evolved Rules Agent with adaptive strategies\n",
    "\n",
    "Idea:\n",
    "The idea was to divide the game into three phases: initial, intermediate and final. Trying to choose the most appropriate moves to make in each phase from the previous strategies. To do this we define a method to understand the phases of the game. And we use a probability to use a specific strategy for each phase. In this way we are able to implement an evolutionary agent with these parameters to be optimized:\n",
    " - **Phase Thresholds**: the thresholds for the phases of the game (early, mid, end)  \n",
    "      We measure the phase of the game by the number of theoretical moves left to end the game over the total number of moves (it thus depends on both size of the board and k-limit): $p\\in [0,1]$  \n",
    "      The thresholds are thus $t_{1}, t_{2} \\in [0,1]$ and the phase is defined as follows:  \n",
    "      - Early phase: $0 \\leq\\ p \\leq t_{1}$\n",
    "      - Mid  phase: $t_{1} < p \\leq t_{2}$\n",
    "      - Late phase: $t_{2} < p\\ < 1$\n",
    " - **Strategy Weights**: values between [1,10] to compute the probabilities of the strategies to be used in each phase, we then normalize them with the softmax function so that we have the actual probability values for each strategy.\n",
    "\n",
    "The fitness of an state is the average of the accuracy of the games played against the *expert* rule-based agent. In this way, we think that probably the Adpative Strategy would collapse to always use the expert system, thus getting to a 50% win rate against him. But, perhaps, the Adpative Strategy could learn that at some stages of the game, playing with other strategies, the expert can be beaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moves_ratio(nim: Nim):\n",
    "    \"\"\"\n",
    "    Compute a value to understand the phase of game.\n",
    "\n",
    "    Args:\n",
    "        state: Nim game instance.\n",
    "\n",
    "    Returns:\n",
    "        A value between 0 and 1 (0 early game -> 1 end game).\n",
    "    \"\"\"\n",
    "    # total possible moves\n",
    "    possible_moves = sum([1 for _, c in enumerate(nim.rows) for _ in range(1, min(c + 1, nim.k))])\n",
    "\n",
    "    inital_nim = Nim(len(nim.rows), nim.k)\n",
    "    # total moves in the start game\n",
    "    total_moves = sum([1 for _, c in enumerate(inital_nim.rows) for _ in range(1, min(c + 1, nim.k))])\n",
    "\n",
    "    return possible_moves / total_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRATEGIES = [expert_system, pure_random, gabriele, optimal]\n",
    "mutation_rate: float = (0.1, 3)\n",
    "\n",
    "\n",
    "@dataclass(init=False)\n",
    "class State:\n",
    "    \"\"\"\n",
    "    Class that define the state for the evolution strategies\n",
    "    \"\"\"\n",
    "\n",
    "    n_strategy: int\n",
    "    phase_thresholds: list[float]\n",
    "    strategy_weights: list[list[float]]\n",
    "\n",
    "    def __init__(self, n_strategy: int = None, strategy_weights=None, phase_thresholds=None) -> None:\n",
    "        if n_strategy is None:\n",
    "            n_strategy = len(STRATEGIES)\n",
    "        if phase_thresholds is None:\n",
    "            phase_thresholds = sorted([random.random(), random.random()])\n",
    "        else:\n",
    "            phase_thresholds = sorted([max(0, phase_thresholds[0]), min(1, phase_thresholds[1])])\n",
    "        if strategy_weights is None:\n",
    "            strategy_weights = np.random.uniform(1, 10, (len(phase_thresholds) + 1, n_strategy))\n",
    "\n",
    "        self.n_strategy = n_strategy\n",
    "        self.strategy_weights = strategy_weights\n",
    "        self.phase_thresholds = phase_thresholds\n",
    "\n",
    "    def mutate(state: \"State\") -> \"State\":\n",
    "        global mutation_rate\n",
    "        state = deepcopy(state)\n",
    "        phase_thresholds = np.clip(np.random.normal(state.phase_thresholds, mutation_rate[0]), 0, 1).tolist()\n",
    "        strategy_weights = np.clip(np.random.normal(state.strategy_weights, mutation_rate[1]), 1, 10).tolist()\n",
    "        return State(strategy_weights=strategy_weights, phase_thresholds=phase_thresholds, n_strategy=state.n_strategy)\n",
    "\n",
    "    def __call__(self: \"State\", state: Nim) -> Nimply:\n",
    "        phase_ratio = moves_ratio(state)\n",
    "        phase_index = (\n",
    "            0\n",
    "            if phase_ratio < self.phase_thresholds[0]\n",
    "            else (1 if self.phase_thresholds[0] <= phase_ratio <= self.phase_thresholds[1] else 2)\n",
    "        )\n",
    "        probs = softmax(self.strategy_weights[phase_index])\n",
    "        strategy = np.random.choice(STRATEGIES, p=probs)\n",
    "        return strategy(state)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Phase thresholds: {self.phase_thresholds}\\nStrategies: {[s.__qualname__ for s in STRATEGIES]}\\nStrategies probs in Early game: {softmax(self.strategy_weights[0])}\\nStrategies probs in Mid game: {softmax(self.strategy_weights[1])}\\nStrategies probs in End game: {softmax(self.strategy_weights[0])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPPONENT = expert_system\n",
    "N_MATCHES = 10\n",
    "\n",
    "\n",
    "def streak(player_strategy, opponent_strategy=OPPONENT, number_of_matches: int = N_MATCHES) -> float:\n",
    "    \"\"\"\n",
    "    Play a given number of random matches between two strategies.\n",
    "\n",
    "    Args:\n",
    "        player_strategy: the player strategy;\n",
    "        opponent_strategy: the opponent strategy;\n",
    "        n_matches: number of matchers to play.\n",
    "\n",
    "    Returns:\n",
    "        Percentage of wins.\n",
    "    \"\"\"\n",
    "    wins = 0\n",
    "    for _ in range(number_of_matches):\n",
    "        random_size = random.randint(4, 10)\n",
    "        random_k = random.randint(2, 10)\n",
    "        nim = Nim(random_size, random_k)\n",
    "        wins += 1 if match(nim, (player_strategy, opponent_strategy)) == 0 else 0\n",
    "    return wins / number_of_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 + $\\lambda$)-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1323176718b4c01933f977ddc6f3693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of solution:\n",
      "Phase thresholds: [0, 0.9832965109861335]\n",
      "Strategies: ['expert_system', 'pure_random', 'gabriele', 'optimal']\n",
      "Strategies probs in Early game: [0.00380678 0.00420187 0.0364653  0.95552606]\n",
      "Strategies probs in Mid game: [9.98506418e-01 4.79051348e-04 5.35479119e-04 4.79051348e-04]\n",
      "Strategies probs in End game: [0.00380678 0.00420187 0.0364653  0.95552606]\n"
     ]
    }
   ],
   "source": [
    "LAMBDA = 40\n",
    "N_MATCHES = 10\n",
    "\n",
    "solution = State()\n",
    "solution_winrate = streak(solution)\n",
    "mutation_rate: float = (0.1, 3)\n",
    "pbar = trange(0, 1_000 // LAMBDA)\n",
    "\n",
    "\n",
    "for i in pbar:\n",
    "    pbar.set_description(f\"Parent Win-rate: {solution_winrate:.2%}\")\n",
    "    offspring = [solution.mutate() for _ in range(LAMBDA)]\n",
    "    results = [streak(i) for i in offspring]\n",
    "    incr_rate = np.sum([res > solution_winrate for res in results]) / LAMBDA\n",
    "\n",
    "    if incr_rate > 1 / 5:\n",
    "        mutation_rate = (mutation_rate[0] * 1.2, mutation_rate[1] * 1.2)\n",
    "\n",
    "    elif incr_rate < 1 / 5:\n",
    "        mutation_rate = (mutation_rate[0] / 1.2, mutation_rate[1] / 1.2)\n",
    "\n",
    "    solution_ind = np.argmax(results)\n",
    "    # update the solution only if it is better than the parent solution\n",
    "\n",
    "    if solution_winrate < results[solution_ind]:\n",
    "        solution = offspring[solution_ind]\n",
    "\n",
    "        solution_winrate = results[solution_ind]\n",
    "\n",
    "    if solution_winrate >= 0.99:\n",
    "        break\n",
    "\n",
    "print(f'Parameters of solution:\\n{solution}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win-rate of adaptive strategy (1 + 𝜆)-ES vs optimal: 95.00%\n",
      "Win-rate of adaptive strategy (1 + 𝜆)-ES vs pure_random: 83.00%\n",
      "Win-rate of adaptive strategy (1 + 𝜆)-ES vs gabriele: 90.00%\n",
      "Win-rate of adaptive strategy (1 + 𝜆)-ES vs expert_system: 63.00%\n"
     ]
    }
   ],
   "source": [
    "nim = Nim(5, 3)\n",
    "opponent_strategies = (optimal, pure_random, gabriele, expert_system)\n",
    "solution.__qualname__ = 'adaptive strategy (1 + 𝜆)-ES'\n",
    "test(nim, solution, opponent_strategys, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1,$\\lambda$)-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e3fb0c868b42e0bd5f00d264da5010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LAMBDA = 40\n",
    "N_MATCHES = 10\n",
    "\n",
    "solution = State()\n",
    "solution_winrate = streak(solution)\n",
    "mutation_rate: float = (0.1, 3)\n",
    "\n",
    "pbar = trange(0, 1_000 // LAMBDA)\n",
    "for i in pbar:\n",
    "    pbar.set_description(f\"Parent Win-rate: {solution_winrate:.2%}\")\n",
    "    offspring = [solution.mutate() for _ in range(LAMBDA)]\n",
    "    results = [streak(i) for i in offspring]\n",
    "\n",
    "    incr_rate = np.sum([res > solution_winrate for res in results]) / LAMBDA\n",
    "\n",
    "    if incr_rate > 1 / 5:\n",
    "        mutation_rate = (mutation_rate[0] * 1.2, mutation_rate[1] * 1.2)\n",
    "    elif incr_rate < 1 / 5:\n",
    "        mutation_rate = (mutation_rate[0] / 1.2, mutation_rate[1] / 1.2)\n",
    "\n",
    "    # always update the solution\n",
    "    solution_ind = np.argmax(results)\n",
    "    solution = offspring[solution_ind]\n",
    "    solution_winrate = results[solution_ind]\n",
    "\n",
    "    if solution_winrate >= 0.99:\n",
    "        break\n",
    "\n",
    "print(f'Parameters of solution:\\n{solution}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win-rate of adaptive strategy (1 , 𝜆)-ES vs optimal: 88.00%\n",
      "Win-rate of adaptive strategy (1 , 𝜆)-ES vs pure_random: 81.00%\n",
      "Win-rate of adaptive strategy (1 , 𝜆)-ES vs gabriele: 94.00%\n",
      "Win-rate of adaptive strategy (1 , 𝜆)-ES vs expert_system: 64.00%\n"
     ]
    }
   ],
   "source": [
    "nim = Nim(5, 3)\n",
    "opponent_strategys = (optimal, pure_random, gabriele, expert_system)\n",
    "solution.__qualname__ = 'adaptive strategy (1 , 𝜆)-ES'\n",
    "test(nim, solution, opponent_strategys, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
